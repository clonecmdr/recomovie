{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task one\n",
    "\n",
    "### Stage 1:\n",
    "\n",
    "Import the input dataset, convert the data types, then save as a\n",
    "parquet file.\n",
    "- schema.json file should be used to load the dataset\n",
    "- The output parquet file must be called: films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/23 13:50:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/23 13:50:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/12/23 13:50:33 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .appName('imdb-munging') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"name.basics.tsv.gz\"\n",
    "path = r'../datasets/%s' % file\n",
    "\n",
    "# Define a Schema\n",
    "schema = 'nconst STRING, primaryName STRING, birthYear DATE, deathYear DATE, primaryProfession STRING, knownForTitles STRING'\n",
    "names = spark.read.csv(path, schema=schema, sep=\"\\t\", header=True, dateFormat=\"yyyy\")\n",
    "\n",
    "names = names.drop('birthYear').drop('deathYear').drop('primaryProfession').drop('knownForTitles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 million move ratings\n",
    "file = \"title.ratings.tsv.gz\"\n",
    "path = r'../datasets/%s' % file\n",
    "\n",
    "# Define a Schema\n",
    "schema = 'tconst STRING not null, averageRating DECIMAL(4,2), numVotes INTEGER'\n",
    "ratings = spark.read.csv(path, schema=schema, sep=\"\\t\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10,248,884 rows\n",
    "file = \"title.principals.tsv.gz\"\n",
    "path = r'../datasets/%s' % file\n",
    "\n",
    "# Define a Schema\n",
    "schema = 'tconst STRING, ordering INTEGER, nconst STRING, category STRING, job STRING, characters STRING'\n",
    "principals = spark.read.csv(path, schema=schema, sep=\"\\t\", header=True).select('tconst', 'nconst', 'ordering', 'job')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"title.basics.tsv.gz\"\n",
    "path = r'../datasets/%s' % file\n",
    "\n",
    "# Define a Schema\n",
    "schema = 'tconst STRING not null, titleType STRING, primaryTitle STRING, originalTitle STRING, isAdult BOOLEAN, startYear DATE, endYear DATE, runtimeMinutes INTEGER, genres STRING'\n",
    "titles = spark.read.csv(path, schema=schema, sep=\"\\t\", header=True, dateFormat=\"yyyy\").select('tconst', 'titleType', 'primaryTitle', 'startYear', 'runtimeMinutes', 'genres')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the ratings to the titles on tconst -> 11_297_218 1_512_899 titles\n",
    "titles = titles.join(ratings, on='tconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nconst: string (nullable = true)\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- ordering: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- primaryName: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join `pricipals` to `names` to get a list of people involved in the film\n",
    "principals = principals.join(names, on='nconst')\n",
    "\n",
    "#principals = principals.sort(['tconst', 'ordering'])\n",
    "\n",
    "# principals is 61_278_693 rows, highest ordering value is 75, \n",
    "# then about #10_248_884 when collect_set() to an array of persons\n",
    "principals.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#principals.groupBy('job').count().sort(f.desc('count')).show(50, truncate=False)\n",
    "#principals.groupBy('job').avg('ordering').show(50, truncate=False)\n",
    "#principals.groupBy('job', 'ordering').count().sort(f.desc('count')).show(50, truncate=False)\n",
    "#principals.filter((principals.job == 'director') & (principals.ordering <= 3)).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'job' column is unreliable\n",
    "#principals = principals.filter(principals.job.isin('\\\\N','director', 'producer', 'writer', 'composer', 'creator'))\\\n",
    "#            .groupby('tconst').agg( f.collect_set('primaryName').alias('persons') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- persons: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perform a reverse explode, do not sort_array() of persons\n",
    "# at this point, principals becomes a key-val table of tconst:[persons]\n",
    "principals = principals.groupby('tconst').agg( f.collect_set('primaryName').alias('persons') )\n",
    "principals.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the number of films down to something more managable\n",
    "titles = titles.filter( (titles['titleType'] == 'movie')\n",
    "                        & (titles['genres'] != '\\\\N')\n",
    "                        & (titles['averageRating'] >= 6) \n",
    "                        & (ratings['numVotes'] >= 500)\n",
    "                        & (titles['runtimeMinutes'].isNotNull())\n",
    "                      ).drop('titleType')\n",
    "\n",
    "# reduced to about 28170 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the genres column an array of geners for each title\n",
    "titles = titles.withColumn(\"genres\", f.split(titles['genres'], r'\\s*,\\s*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the principals (persons) array for each film\n",
    "titles = titles.join(principals, on='tconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitise the column names\n",
    "col_names = {'tconst': 'film_id', \n",
    "            'primaryTitle': 'title', \n",
    "            'startYear': 'year', \n",
    "            'runtimeMinutes': 'duration', \n",
    "            'primaryName': 'person',\n",
    "            'averageRating': 'rating', \n",
    "            'numVotes': 'vote_count'}\n",
    "titles = titles.withColumnsRenamed(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip the leading \"tt\" from the film_id\n",
    "titles = titles.withColumn('film_id', f.replace( titles.film_id, f.lit('tt'), f.lit('') ).cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"fields\":[{\"metadata\":{},\"name\":\"film_id\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"title\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"year\",\"nullable\":true,\"type\":\"date\"},{\"metadata\":{},\"name\":\"duration\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"genres\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"string\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"rating\",\"nullable\":true,\"type\":\"decimal(4,2)\"},{\"metadata\":{},\"name\":\"vote_count\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"persons\",\"nullable\":false,\"type\":{\"containsNull\":false,\"elementType\":\"string\",\"type\":\"array\"}}],\"type\":\"struct\"}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles.schema.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- film_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: date (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- rating: decimal(4,2) (nullable = true)\n",
      " |-- vote_count: integer (nullable = true)\n",
      " |-- persons: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/23 01:50:46 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "titles.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write the processed IMDB data to a parquet file\n",
    "path = \"../output/films\"\n",
    "titles.write.parquet(path, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [cast(replace(tconst#50, tt, ) as int) AS film_id#135, primaryTitle#52 AS title#126, startYear#55 AS year#124, runtimeMinutes#57 AS duration#121, genres#105, averageRating#28 AS rating#123, numVotes#29 AS vote_count#125, persons#95]\n",
      "   +- SortMergeJoin [tconst#50], [tconst#33], Inner\n",
      "      :- Sort [tconst#50 ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(tconst#50, 200), ENSURE_REQUIREMENTS, [plan_id=661]\n",
      "      :     +- Project [tconst#50, primaryTitle#52, startYear#55, runtimeMinutes#57, split(genres#58, \\s*,\\s*, -1) AS genres#105, averageRating#28, numVotes#29]\n",
      "      :        +- BroadcastHashJoin [tconst#50], [tconst#27], Inner, BuildRight, false\n",
      "      :           :- Project [tconst#50, primaryTitle#52, startYear#55, runtimeMinutes#57, genres#58]\n",
      "      :           :  +- Filter (((((isnotnull(titleType#51) AND isnotnull(genres#58)) AND (titleType#51 = movie)) AND NOT (genres#58 = \\N)) AND isnotnull(runtimeMinutes#57)) AND isnotnull(tconst#50))\n",
      "      :           :     +- FileScan csv [tconst#50,titleType#51,primaryTitle#52,startYear#55,runtimeMinutes#57,genres#58] Batched: false, DataFilters: [isnotnull(titleType#51), isnotnull(genres#58), (titleType#51 = movie), NOT (genres#58 = \\N), isn..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/alex/work/Solirius/film-reco/datasets/title.basics.tsv.gz], PartitionFilters: [], PushedFilters: [IsNotNull(titleType), IsNotNull(genres), EqualTo(titleType,movie), Not(EqualTo(genres,\\N)), IsNo..., ReadSchema: struct<tconst:string,titleType:string,primaryTitle:string,startYear:date,runtimeMinutes:int,genre...\n",
      "      :           +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=645]\n",
      "      :              +- Filter ((((isnotnull(averageRating#28) AND isnotnull(numVotes#29)) AND (averageRating#28 >= 6.00)) AND (numVotes#29 >= 500)) AND isnotnull(tconst#27))\n",
      "      :                 +- FileScan csv [tconst#27,averageRating#28,numVotes#29] Batched: false, DataFilters: [isnotnull(averageRating#28), isnotnull(numVotes#29), (averageRating#28 >= 6.00), (numVotes#29 >=..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/alex/work/Solirius/film-reco/datasets/title.ratings.tsv.gz], PartitionFilters: [], PushedFilters: [IsNotNull(averageRating), IsNotNull(numVotes), GreaterThanOrEqual(averageRating,6.00), GreaterTh..., ReadSchema: struct<tconst:string,averageRating:decimal(4,2),numVotes:int>\n",
      "      +- Sort [tconst#33 ASC NULLS FIRST], false, 0\n",
      "         +- ObjectHashAggregate(keys=[tconst#33], functions=[collect_set(primaryName#1, 0, 0)])\n",
      "            +- Exchange hashpartitioning(tconst#33, 200), ENSURE_REQUIREMENTS, [plan_id=657]\n",
      "               +- ObjectHashAggregate(keys=[tconst#33], functions=[partial_collect_set(primaryName#1, 0, 0)])\n",
      "                  +- Project [tconst#33, primaryName#1]\n",
      "                     +- SortMergeJoin [nconst#35], [nconst#0], Inner\n",
      "                        :- Sort [nconst#35 ASC NULLS FIRST], false, 0\n",
      "                        :  +- Exchange hashpartitioning(nconst#35, 200), ENSURE_REQUIREMENTS, [plan_id=649]\n",
      "                        :     +- Filter (isnotnull(nconst#35) AND isnotnull(tconst#33))\n",
      "                        :        +- FileScan csv [tconst#33,nconst#35] Batched: false, DataFilters: [isnotnull(nconst#35), isnotnull(tconst#33)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/alex/work/Solirius/film-reco/datasets/title.principals.tsv.gz], PartitionFilters: [], PushedFilters: [IsNotNull(nconst), IsNotNull(tconst)], ReadSchema: struct<tconst:string,nconst:string>\n",
      "                        +- Sort [nconst#0 ASC NULLS FIRST], false, 0\n",
      "                           +- Exchange hashpartitioning(nconst#0, 200), ENSURE_REQUIREMENTS, [plan_id=650]\n",
      "                              +- Filter isnotnull(nconst#0)\n",
      "                                 +- FileScan csv [nconst#0,primaryName#1] Batched: false, DataFilters: [isnotnull(nconst#0)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/alex/work/Solirius/film-reco/datasets/name.basics.tsv.gz], PartitionFilters: [], PushedFilters: [IsNotNull(nconst)], ReadSchema: struct<nconst:string,primaryName:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titles.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
